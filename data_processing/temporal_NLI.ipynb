{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "import pandas as pd\n",
    "\n",
    "# Load the SNLI dataset\n",
    "snli = load_dataset('snli')\n",
    "\n",
    "# Access different splits\n",
    "train_data = snli['train']\n",
    "validation_data = snli['validation']\n",
    "test_data = snli['test']\n",
    "\n",
    "# Print a few examples\n",
    "print(train_data[0])\n",
    "print(validation_data[0])\n",
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Define temporal keywords\n",
    "temporal_keywords = [\n",
    "    # Explicit references\n",
    "    'today', 'tomorrow', 'yesterday', 'now', 'soon', 'later', 'before', 'after',\n",
    "    'day', 'week', 'month', 'year', 'hour', 'minute', 'second', 'morning',\n",
    "    'evening', 'night', 'noon', 'midnight', 'anniversary',\n",
    "    \n",
    "    # Days of the week\n",
    "    'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday',\n",
    "    \n",
    "    # Months\n",
    "    'January', 'February', 'March', 'April', 'May', 'June',\n",
    "    'July', 'August', 'September', 'October', 'November', 'December',\n",
    "\n",
    "    # Seasons\n",
    "    'spring', 'summer', 'fall', 'autumn', 'winter',\n",
    "\n",
    "    # Periods & Eras\n",
    "    'decade', 'century', 'millennium', 'epoch', 'era', \n",
    "\n",
    "    # General terms\n",
    "    'annual', 'biannual', 'quarterly', 'hourly', 'daily', 'weekly', 'quarter',\n",
    "    'monthly', 'fortnight', 'biweekly', 'bimonthly', 'semester', 'trimester',\n",
    "    \n",
    "    # Relative terms\n",
    "    'past', 'future', 'current', 'upcoming', 'recent', 'lately', 'ago', 'in advance', 'later',\n",
    "    'previous', 'next', 'moment', 'time', 'when', 'while', 'duration', 'period', 'early', 'earlier',\n",
    "\n",
    "    # Implicit/temporal actions\n",
    "    'wait', 'postpone', 'delay', 'reschedule', 'expire', 'due', 'schedule',\n",
    "    'begin', 'start', 'end', 'finish', 'commence', 'conclude', 'last', 'extend',\n",
    "\n",
    "    # Temporal transitions & connectors\n",
    "    'until', 'by the time', 'as soon as', 'whenever', 'since', 'during', 'whilst',\n",
    "\n",
    "    # Other temporal entities\n",
    "    'sunset', 'sunrise', 'dusk', 'dawn', 'midday', 'eve', 'annually', 'eventually',\n",
    "    'seldom', 'often', 'always', 'never', 'sometimes', 'usually', 'frequently', \n",
    "    'occasionally', 'rarely', 'just', 'once', 'still'\n",
    "]\n",
    "\n",
    "def contains_temporal_keyword(sentence):\n",
    "    \"\"\"Return True if the sentence contains any temporal keyword, else False.\"\"\"\n",
    "    sentence = sentence.lower()\n",
    "    for keyword in temporal_keywords:\n",
    "        # Search for whole word matches\n",
    "        if re.search(r'\\b' + keyword + r'\\b', sentence):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_temporal(example):\n",
    "    \"\"\"Return True if either premise or hypothesis contains a temporal keyword.\"\"\"\n",
    "    premise = example['premise']\n",
    "    hypothesis = example['hypothesis']\n",
    "    return contains_temporal_keyword(premise) or contains_temporal_keyword(hypothesis)\n",
    "\n",
    "# Filter temporally relevant sentences\n",
    "train_temporal = snli['train'].filter(is_temporal)\n",
    "validation_temporal = snli['validation'].filter(is_temporal)\n",
    "test_temporal = snli['test'].filter(is_temporal)\n",
    "\n",
    "# Print a few examples\n",
    "print(train_temporal[0])\n",
    "print(validation_temporal[0])\n",
    "print(test_temporal[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the datasets\n",
    "all_temporal = concatenate_datasets([train_temporal, validation_temporal, test_temporal])\n",
    "\n",
    "# Convert the combined dataset into a list of dictionaries\n",
    "all_temporal_list = [{\"premise\": p, \"hypothesis\": h, \"label\": l} for p, h, l in zip(all_temporal[\"premise\"], all_temporal[\"hypothesis\"], all_temporal[\"label\"])]\n",
    "\n",
    "def format_example(example):\n",
    "    label_to_option = {0: \"entailment\", 1: \"neutral\", 2: \"contradiction\"}\n",
    "    \n",
    "    formatted_example = {\n",
    "        \"Premise\": example[\"premise\"],\n",
    "        \"Hypothesis\": example[\"hypothesis\"],\n",
    "        \"Option A\": \"entailment\",\n",
    "        \"Option B\": \"neutral\",\n",
    "        \"Option C\": \"contradiction\",\n",
    "        \"Answer\": chr(65 + example[\"label\"])  # Converts 0 to A, 1 to B, and 2 to C\n",
    "    }\n",
    "    return formatted_example\n",
    "\n",
    "formatted_data = [format_example(example) for example in all_temporal_list]\n",
    "temporal_snli_df = pd.DataFrame(formatted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli = load_dataset('glue', 'mnli')\n",
    "train_data = mnli['train']\n",
    "validation_matched_data = mnli['validation_matched']\n",
    "validation_mismatched_data = mnli['validation_mismatched']\n",
    "\n",
    "# Print a few examples\n",
    "print(train_data[0])\n",
    "print(validation_matched_data[0])\n",
    "print(validation_mismatched_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filter temporally relevant sentences\n",
    "train_temporal = mnli['train'].filter(is_temporal)\n",
    "validation_matched_temporal = mnli['validation_matched'].filter(is_temporal)\n",
    "validation_mismatched_temporal = mnli['validation_mismatched'].filter(is_temporal)\n",
    "\n",
    "# Print a few examples\n",
    "print(train_temporal[0])\n",
    "print(validation_matched_temporal[0])\n",
    "print(validation_mismatched_temporal[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the datasets\n",
    "all_temporal = concatenate_datasets([train_temporal, validation_matched_temporal, validation_mismatched_temporal])\n",
    "\n",
    "# Convert the combined dataset into a list of dictionaries\n",
    "all_temporal_list = [{\"premise\": p, \"hypothesis\": h, \"label\": l} for p, h, l in zip(all_temporal[\"premise\"], all_temporal[\"hypothesis\"], all_temporal[\"label\"])]\n",
    "\n",
    "formatted_data = [format_example(example) for example in all_temporal_list]\n",
    "temporal_mnli_df = pd.DataFrame(formatted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_snli_df['Category'] = 'SNLI'\n",
    "temporal_mnli_df['Category'] = 'MNLI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temporal_nli = pd.concat([temporal_snli_df, temporal_mnli_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temporal_nli = df_temporal_nli.drop_duplicates(subset=['Premise', 'Hypothesis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temporal_nli = df_temporal_nli[~df_temporal_nli['Answer'].str.contains(\"@\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
